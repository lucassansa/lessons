{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1.3: Intro to Pandas\n",
    "\n",
    "### Lesson Duration: 3 hours\n",
    "\n",
    "> Purpose: The purpose of this lesson is to understand the different types of data that we come across as analysts. The students will learn conducting similar data wrangling operations that were implemented in MS Excel including reading data into Python, blending data, working with columns, filtering, and subsetting operations.\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- Merge or blend data from multiple sources using Pandas in Python\n",
    "- Work with NumPy and Pandas, both Python essential libraries for data analysis.\n",
    "- Perform basic data pre-processing operations on dataframes.\n",
    "\n",
    "> :exclamation: Important note: It is important to emphasize that having sharp business acumen is a very important skill for data analysts.\n",
    "> An analyst should have good knowledge about the business function that they are helping with the analysis, asking the right set of questions to the clients/stakeholders involved, understanding what are the factors that are driving the business. It is also critical to understand the limitations of the analysis based on the availability of data, do we have the right data to answer the questions that we are trying to solve or would we need more data, and if yes, data on what parameters would we need.\n",
    "\n",
    "### Lesson 1 key concepts\n",
    "\n",
    "> :clock10: 20 min\n",
    "\n",
    "Features and labels, data types in data analysis\n",
    "\n",
    "- Numerical data\n",
    "- Categorical data (nominal, ordinal)\n",
    "- Text data for NLP\n",
    "- Media data - image, video, voice/speech\n",
    "\n",
    "<details>\n",
    "  <summary> Engagement strategies for using pandas library, reading files and data blending </summary>\n",
    "\n",
    ":exclamation: This might be the first time the students will use a Python library.\n",
    "\n",
    "> Give an introduction to the library, aliasing, keywords, methods available.\n",
    "> Open the files using a text editor and show the students how the files are stored based on the file extensions. Ex. the difference between files such as `CSV`, tab-separated values, pipe separated values, etc.\n",
    "> We are using 4 files in this lesson. Show the students how to use `concat` with 2 files (as you will see in the following Code Sample, you can use `file1.csv` and `file2.txt`), and ask them to read and `concat` the other two files themselves as hands-on practice.\n",
    "> At this stage it is important to move slowly as the students would be fairly new to using Python libraries. Emphasize the importance to go through the documentation for different functions, etc. At different stages, it is also important to emphasize that the students should play around with the code and analyze the changes in the output.\n",
    "\n",
    "</details>\n",
    "\n",
    "- Reading data into Jupyter and data cleaning operations in Python using pandas and NumPy:\n",
    "  - Introduction to pandas\n",
    "  - Reading flat files and data blending\n",
    "  - Standardizing, renaming headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # explain keywords are highlighted in green, other strings in red, etc.\n",
    "import numpy as np\n",
    "\n",
    "# Reading data\n",
    "file1 = pd.read_csv('./files_for_lesson_and_activities/file1.csv')\n",
    "file1.head()\n",
    "file2 = pd.read_csv('./files_for_lesson_and_activities/file2.txt', sep = '\\t')  # Show them to read and concat 2 files , other two will be done by students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data blending\n",
    "column_names = file1.columns\n",
    "data = pd.DataFrame(columns=column_names)\n",
    "data = pd.concat([data,file1, file2], axis=0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Diagram for concatenation](https://education-team-2020.s3-eu-west-1.amazonaws.com/data-analytics/1.3+-+Axes+Explain+-+Data.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing header names\n",
    "cols = []\n",
    "for i in range(len(data.columns)):\n",
    "    cols.append(data.columns[i].lower())\n",
    "data.columns = cols\n",
    "\n",
    "# renaming columns\n",
    "data = data.rename(columns={ 'controln':'id','hv1':'median_home_val', 'ic1':'median_household_income'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### :pencil2: Check for Understanding - Class activity/quick quiz\n",
    "\n",
    "> :clock10: 15 min (+ 5 min Review)\n",
    "\n",
    "# 1.03 Activity 1\n",
    "\n",
    "Refer to the folder `files_for_activities` for this exercise. **You can continue using the same jupyter notebook that you craeted in class (where you worked on file1 and file2). Please save your work (jupyter notebook) as we will build on the same activities later.**\n",
    "\n",
    "1. Load data (`file3.xlsx` and `file4.xlsx`) in a new Jupyter notebook. You might face the error saying that optional dependency _xlrd_ is missing. In that case, they should install it using `pip`. If you don't get the error, move to the next step. :smile:\n",
    "2. Print data columns for both files.\n",
    "3. Check the names and order of columns in the files, and compare them with the \"data\" DataFrame created in class.\n",
    "4. Change the names of required columns in the new dataframes read before concatenating the files with data.\n",
    "5. Change data columns from uppercase to lowercase.\n",
    "\n",
    "\n",
    "_We will merge the dataframes in the next exercise_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some students might get error saying that optional dependency openpyxl is missing\n",
    "# in that case, use the following line:\n",
    "# pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file3 = pd.read_excel(\"./files_for_lesson_and_activities/file3.xlsx\", engine=\"openpyxl\")\n",
    "file4 = pd.read_excel('./files_for_lesson_and_activities/file4.xlsx', engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file3.columns\n",
    "file4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file3 = file3.rename(columns={ 'controln':'id','hv1':'median_home_val', 'ic1':'median_household_income'})\n",
    "file4 = file4.rename(columns={ 'controln':'id','hv1':'median_home_val', 'ic1':'median_household_income'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols1=[]\n",
    "for c in file3.columns:\n",
    "    cols1.append(c.lower())\n",
    "\n",
    "file3.columns=cols1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly for the other dataframe:\n",
    "cols2=[]\n",
    "for c in file4.columns:\n",
    "    cols2.append(c.lower())\n",
    "\n",
    "file4.columns=cols2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 2 key concepts\n",
    "\n",
    "> :clock10: 20 min\n",
    "\n",
    "Data wrangling/cleaning using Python:\n",
    "\n",
    "- Deleting columns\n",
    "- Rearranging columns\n",
    "- Filtering and subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting columns\n",
    "data = data.drop(['tcode'], axis =1) # Explain the argument axis, when axis is 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging columns\n",
    "data = data[['id', 'state', 'gender', 'median_home_val', 'median_household_income', 'ic2', 'ic3', 'ic4', 'ic5', 'avggift', 'domain', 'dob', 'target_d']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering and subsetting -- using conditions with DataFrame\n",
    "data[data['gender']=='M']\n",
    "data[data['gender'].isin(['M', 'F'])]\n",
    "data[(data['gender']=='M') | (data['gender']=='F')]\n",
    "data[data['target_d']>100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### :pencil2: Check for Understanding - Class activity/quick quiz\n",
    "\n",
    "> :clock10: 15 min (+ 5 min Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.03 Activity 2\n",
    "\n",
    "(_Keep using the same notebook you used in the activity 1._)\n",
    "\n",
    "1. Merge the 'data' dataframe you created in class with the dataframes for 'file3' and 'file4' you created in the last activity. If you are not able to merge the dataframes, please take a look at the order of columns and/or the shape of the dataframes (specifically the number of columns in the dataframes). Also check the shape of the new dataframe\n",
    "2. Drop the columns `domain` and `dob`\n",
    "3. Rearrange the columns by placing columns `ic2`, `ic3`, `ic4`, `ic5` before the column `median_home_val`\n",
    "4. Filter the rows for men that live in Florida. Do not store the results in data.\n",
    "5. Filter the rows for female donors that have donated less than 100. Do not store the results in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "data = pd.concat([data,file3, file4], axis=0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "data = data.drop(['domain', 'dob'], axis =1) # Explain the argument axis, when axis is 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "data = data[['id', 'state', 'gender', 'ic2', 'ic3', 'ic4', 'ic5', 'median_home_val', 'median_household_income', 'avggift', 'target_d']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "data[(data['gender']=='M') & (data['state']=='FL')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "data[(data['target_d']<100) & (data['gender']=='F')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 3 key concepts\n",
    "\n",
    "> :clock10: 20 min\n",
    "\n",
    "More data wrangling/cleaning with Python:\n",
    "\n",
    "- Reset index\n",
    "- Working with indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter and reset the index\n",
    "\n",
    "# In this section again emphasize on the importance of playing with the code and checking the output\n",
    "filtered = data[data['gender']=='M']  # Lets say that we are working on this filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered\n",
    "filtered = filtered.reset_index(drop=True)\n",
    "# temp = filtered.copy()\n",
    "# temp.set_index('state') # This is a dummy case, but indexes should be unique and not nulls, usually auto-increments by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with indexes\n",
    "filtered[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered[['gender', 'ic2', 'ic3']][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.loc[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.loc[100]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.iloc[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, working just on the indexes row,columns\n",
    "filtered.iloc[1:10,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.iloc[[1,2,3,4],[0,2,4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### :pencil2: Check for Understanding - Class activity/quick quiz\n",
    "\n",
    "> :clock10: 10 min (+ 5 min Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.03 Activity 3\n",
    "\n",
    "(_Keep using the same notebook you used in the activity 1._)\n",
    "\n",
    "1. Filter the results for women, and store the results in another DataFrame `filtered2`.\n",
    "2. Check the first 10 rows of the DataFrame using the `head()` function.\n",
    "3. Reset the index of `filtered2` with and without using the parameter `drop=True` and check the difference in the results.\n",
    "4. Show the rows from index number 100 to 200.\n",
    "5. Use `iloc` to get the first 100 rows and columns with indexes 2,3,4,5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "filtered2 = data[data['gender']=='F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "filtered2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "filtered2.reset_index()\n",
    "filtered2 = filtered2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "filtered2[100:201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "filtered2.iloc[0:101,2:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 4 key concepts\n",
    "\n",
    "> :clock10: 20 min\n",
    "\n",
    "Data cleaning operations with Python\n",
    "\n",
    "- Correcting data types\n",
    "- Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data types\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data._get_numeric_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data._get_bool_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcting data types\n",
    "data['median_home_val'] =  pd.to_numeric(data['median_home_val'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ic5'] =  pd.to_numeric(data['ic5'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data._get_numeric_data() # to check if 'median_home_val' and 'ic5' are now listed as numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicates\n",
    "data = data.drop_duplicates()  # play around with the code, show them how to use keep argument\n",
    "# temp = temp.drop_duplicates(subset=['state','gender', 'ic2', 'ic3'])\n",
    "# if we want to remove duplicates based on some specific columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### :pencil2: Check for Understanding - Class activity/quick quiz\n",
    "\n",
    "> :clock10: 10 min (+ 5 min Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.03 Activity 4\n",
    "\n",
    "(_Keep using the same notebook you used in the activity 1._)\n",
    "\n",
    "1. Check the data types of all the columns in the DataFrame.\n",
    "2. Use `select_dtypes()` to select all the numerical columns in the DataFrame (both integers and floats).\n",
    "3. Convert the columns that have numerical values (which are now object types) to the numeric type.\n",
    "4. Remove duplicates from the DataFrame if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "data.select_dtypes(['int32', 'float64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "data['median_household_income'] =  pd.to_numeric(data['median_household_income'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ic3'] =  pd.to_numeric(data['ic3'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### :pencil2: Practice on key concepts - Lab\n",
    "\n",
    "> :clock10: 45 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Customer Analysis Round 1\n",
    "\n",
    "#### Remember the process:\n",
    "\n",
    "1. Case Study\n",
    "2. Get data\n",
    "3. Cleaning/Wrangling/EDA\n",
    "4. Processing Data\n",
    "5. Modeling\n",
    "6. Validation\n",
    "7. Reporting\n",
    "\n",
    "### Abstract\n",
    "\n",
    "The objective of this data is to understand customer demographics and buying behavior. Later during the week, we will use predictive analytics to analyze the most profitable customers and how they interact. After that, we will take targeted actions to increase profitable customer response, retention, and growth.\n",
    "\n",
    "For this lab, we will gather the data from 3 _csv_ files that are provided in the `files_for_lab` folder. Use that data and complete the data cleaning tasks as mentioned later in the instructions.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Read the three files into python as dataframes\n",
    "- Show the DataFrame's shape.\n",
    "- Standardize header names.\n",
    "- Rearrange the columns in the dataframe as needed\n",
    "- Concatenate the three dataframes\n",
    "- Which columns are numerical?\n",
    "- Which columns are categorical?\n",
    "- Understand the meaning of all columns\n",
    "- Perform the data cleaning operations mentioned so far in class\n",
    "\n",
    "  - Delete the column education and the number of open complaints from the dataframe.\n",
    "  - Correct the values in the column customer lifetime value. They are given as a percent, so multiply them by 100 and change `dtype` to `numerical` type.\n",
    "  - Check for duplicate rows in the data and remove if any.\n",
    "  - Filter out the data for customers who have an income of 0 or less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Resources\n",
    "\n",
    "- [String functions - documentation](https://docs.python.org/2.5/lib/string-methods.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
